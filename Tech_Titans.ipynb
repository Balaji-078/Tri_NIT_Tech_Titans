{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balaji-078/Tri_NIT_Tech_Titans/blob/main/Tech_Titans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5M7R4rf_XsL",
        "outputId": "9b9a1361-88b0-4695-bb7e-8f2be9eb063b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    # Encode the URL to handle non-ASCII characters\n",
        "    encoded_url = quote(url, safe=':/')\n",
        "    # Stream the data from the URL\n",
        "    with requests.get(encoded_url, stream=True) as response:\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as file:\n",
        "                # Iterate over the response data in chunks and write to file\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "            print(\"Download complete!\")\n",
        "        else:\n",
        "            print(\"Failed to download file\")\n",
        "\n",
        "# Example usage\n",
        "url = \"https://bigdatacup.s3.ap-northeast-1.amazonaws.com/2022/CRDDC2022/RDD2022/Country_Specific_Data_CRDDC2022/RDD2022_Japan.zip\"\n",
        "save_path = \"Japan.zip\"\n",
        "download_file(url, save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iXNnrPx_Xor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tevvK1hn_Xl4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxKUGXnU_XjB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVMGulXh_XgZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFRwnOVsCFhb",
        "outputId": "5e840f6c-5b5b-4de6-fe33-e698a9666547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    # Encode the URL to handle non-ASCII characters\n",
        "    encoded_url = quote(url, safe=':/')\n",
        "    # Stream the data from the URL\n",
        "    with requests.get(encoded_url, stream=True) as response:\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as file:\n",
        "                # Iterate over the response data in chunks and write to file\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "            print(\"Download complete!\")\n",
        "        else:\n",
        "            print(\"Failed to download file\")\n",
        "\n",
        "# Example usage\n",
        "url = \"https://bigdatacup.s3.ap-northeast-1.amazonaws.com/2022/CRDDC2022/RDD2022/Country_Specific_Data_CRDDC2022/RDD2022_Japan.zip\"\n",
        "save_path = \"Japan.zip\"\n",
        "download_file(url, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxV_5qNiCGDA",
        "outputId": "e3c569d4-914b-4765-9c80-d869a786ca03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    # Encode the URL to handle non-ASCII characters\n",
        "    encoded_url = quote(url, safe=':/')\n",
        "    # Stream the data from the URL\n",
        "    with requests.get(encoded_url, stream=True) as response:\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as file:\n",
        "                # Iterate over the response data in chunks and write to file\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "            print(\"Download complete!\")\n",
        "        else:\n",
        "            print(\"Failed to download file\")\n",
        "\n",
        "# Example usage\n",
        "url = \"https://bigdatacup.s3.ap-northeast-1.amazonaws.com/2022/CRDDC2022/RDD2022/Country_Specific_Data_CRDDC2022/RDD2022_Czech.zip\"\n",
        "save_path = \"Czech.zip\"\n",
        "download_file(url, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YDdMp-VCGhD",
        "outputId": "9d8c147e-9c98-4e05-f192-a6a402d14432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    # Encode the URL to handle non-ASCII characters\n",
        "    encoded_url = quote(url, safe=':/')\n",
        "    # Stream the data from the URL\n",
        "    with requests.get(encoded_url, stream=True) as response:\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as file:\n",
        "                # Iterate over the response data in chunks and write to file\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "            print(\"Download complete!\")\n",
        "        else:\n",
        "            print(\"Failed to download file\")\n",
        "\n",
        "# Example usage\n",
        "url = \"https://bigdatacup.s3.ap-northeast-1.amazonaws.com/2022/CRDDC2022/RDD2022/Country_Specific_Data_CRDDC2022/RDD2022_India.zip\"\n",
        "save_path = \"India.zip\"\n",
        "download_file(url, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXmsvOgwC1wU"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_file, extract_to):\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "\n",
        "    # Open the zip file\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        # Extract all contents to the specified directory\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chYaYqFHDloD"
      },
      "outputs": [],
      "source": [
        "zip_file = 'Czech.zip'  # Replace with the path to your zip file\n",
        "extract_to = 'Czech'  # Replace with the path where you want to extract the contents\n",
        "unzip_file(zip_file, extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaGOttUBD0pa"
      },
      "outputs": [],
      "source": [
        "zip_file = 'India.zip'  # Replace with the path to your zip file\n",
        "extract_to = 'India'  # Replace with the path where you want to extract the contents\n",
        "unzip_file(zip_file, extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDpFaFjkD3Gg"
      },
      "outputs": [],
      "source": [
        "zip_file = 'Japan.zip'  # Replace with the path to your zip file\n",
        "extract_to = 'Japan'  # Replace with the path where you want to extract the contents\n",
        "unzip_file(zip_file, extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myQh-0G0EHtb"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def copy_images(source_folder, destination_folder):\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Iterate through each file in the source folder\n",
        "    for filename in os.listdir(source_folder):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "            # Construct the full path of the source and destination files\n",
        "            source_file = os.path.join(source_folder, filename)\n",
        "            destination_file = os.path.join(destination_folder, filename)\n",
        "\n",
        "            # Copy the file to the destination folder\n",
        "            shutil.copyfile(source_file, destination_file)\n",
        "            # print(f\"Copied {source_file} to {destination_file}\")\n",
        "\n",
        "# Example usage:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9XCqGU1FeYO"
      },
      "outputs": [],
      "source": [
        "def copy_xml(source_folder, destination_folder):\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Iterate through each file in the source folder\n",
        "    for filename in os.listdir(source_folder):\n",
        "        if filename.endswith(('.xml')):\n",
        "            # Construct the full path of the source and destination files\n",
        "            source_file = os.path.join(source_folder, filename)\n",
        "            destination_file = os.path.join(destination_folder, filename)\n",
        "\n",
        "            # Copy the file to the destination folder\n",
        "            shutil.copyfile(source_file, destination_file)\n",
        "            # print(f\"Copied {source_file} to {destination_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZEqufe_EliK"
      },
      "outputs": [],
      "source": [
        "source_folder = 'Czech/Czech/train/images'  # Replace with the path to your source images folder\n",
        "destination_folder = 'images'  # Replace with the path to the destination folder\n",
        "copy_images(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjrbqm7_E53G"
      },
      "outputs": [],
      "source": [
        "source_folder = 'India/India/train/images'  # Replace with the path to your source images folder\n",
        "destination_folder = 'images'  # Replace with the path to the destination folder\n",
        "copy_images(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLuPPN_mE7VS"
      },
      "outputs": [],
      "source": [
        "source_folder = 'Japan/Japan/train/images'  # Replace with the path to your source images folder\n",
        "destination_folder = 'images'  # Replace with the path to the destination folder\n",
        "copy_images(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut-AfhQ7FYLM"
      },
      "outputs": [],
      "source": [
        "source_folder = 'Czech/Czech/train/annotations/xmls'  # Replace with the path to your source images folder\n",
        "destination_folder = 'annotations_xml'  # Replace with the path to the destination folder\n",
        "copy_xml(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqdBqlEeFnnN"
      },
      "outputs": [],
      "source": [
        "source_folder = 'India/India/train/annotations/xmls'  # Replace with the path to your source images folder\n",
        "destination_folder = 'annotations_xml'  # Replace with the path to the destination folder\n",
        "copy_xml(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUJVA8MqFoBV"
      },
      "outputs": [],
      "source": [
        "source_folder = 'Japan/Japan/train/annotations/xmls'  # Replace with the path to your source images folder\n",
        "destination_folder = 'annotations_xml'  # Replace with the path to the destination folder\n",
        "copy_xml(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbX03M9DGLan"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaZUwwPvFQAY",
        "outputId": "4b3dceb9-a5a4-4df4-d6c1-f644f98422cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the folder: 21041\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_images(folder_path):\n",
        "    # Initialize a variable to count the number of images\n",
        "    image_count = 0\n",
        "\n",
        "    # Iterate through each file in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # Check if the file is an image by checking its extension\n",
        "        if filename.endswith(('.xml')):\n",
        "            image_count += 1\n",
        "\n",
        "    return image_count\n",
        "\n",
        "# Example usage:\n",
        "folder_path = 'annotations_xml'  # Replace with the path to your folder\n",
        "num_images = count_images(folder_path)\n",
        "print(f\"Number of images in the folder: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR41Rx5Byy8j"
      },
      "outputs": [],
      "source": [
        "def xml_to_yolo(xml_file_path, output_folder):\n",
        "    # Parse the XML file\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Get the image filename\n",
        "    filename = root.find('filename').text\n",
        "\n",
        "    # Create or open the text file in the output folder\n",
        "    output_file = open(os.path.join(output_folder, filename.split('.')[0] + '.txt'), 'w')\n",
        "\n",
        "    # Iterate through each object in the XML\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        bbox = obj.find('bndbox')\n",
        "\n",
        "        # Extract bounding box coordinates\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        # Calculate bounding box center and width/height\n",
        "        x_center = (xmin + xmax) / 2\n",
        "        y_center = (ymin + ymax) / 2\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        # Normalize bounding box coordinates\n",
        "        img_width = int(root.find('size').find('width').text)\n",
        "        img_height = int(root.find('size').find('height').text)\n",
        "        x_center /= img_width\n",
        "        y_center /= img_height\n",
        "        width /= img_width\n",
        "        height /= img_height\n",
        "\n",
        "        # Write YOLO v8 style annotation to the text file\n",
        "        class_id = classes[class_name]\n",
        "        output_file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    # Close the output file\n",
        "    output_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMgV-KJOJdIF",
        "outputId": "9527fbf8-8bf5-4461-bc04-c78bfcc49c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'D50': 0, 'D20': 1, 'D00': 2, 'D44': 3, 'D10': 4, 'D40': 5, 'D43': 6, 'D01': 7, 'D11': 8, 'D0w0': 9}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "classes={}\n",
        "c=0\n",
        "for file_name in os.listdir('annotations_xml'):\n",
        "    if file_name.endswith('.xml'):\n",
        "        xml_file_path = os.path.join('annotations_xml', file_name)\n",
        "        tree = ET.parse(xml_file_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "\n",
        "        # Get the image filename\n",
        "        filename = root.find('filename').text\n",
        "\n",
        "        # Iterate through each object in the XML\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = c\n",
        "                c+=1\n",
        "\n",
        "print(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "classes = {}\n",
        "class_counts = {}\n",
        "\n",
        "c = 0\n",
        "for file_name in os.listdir('annotations_xml'):\n",
        "    if file_name.endswith('.xml'):\n",
        "        xml_file_path = os.path.join('annotations_xml', file_name)\n",
        "        tree = ET.parse(xml_file_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Get the image filename\n",
        "        filename = root.find('filename').text\n",
        "\n",
        "        # Iterate through each object in the XML\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = c\n",
        "                class_counts[class_name] = 1\n",
        "                c += 1\n",
        "            else:\n",
        "                class_counts[class_name] += 1\n",
        "\n",
        "print(\"Total classes:\", len(classes))\n",
        "print(\"Number of data points in each class:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa-YtJoLcnEV",
        "outputId": "1ecfa716-21ad-4af7-80c2-05dac7288042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total classes: 10\n",
            "Number of data points in each class:\n",
            "D50: 3581\n",
            "D20: 8381\n",
            "D00: 6592\n",
            "D44: 5057\n",
            "D10: 4446\n",
            "D40: 5627\n",
            "D43: 793\n",
            "D01: 179\n",
            "D11: 45\n",
            "D0w0: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-08n-SRysSw",
        "outputId": "119d5eb9-624e-4c33-9347-60604f2440c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion successful. YOLO v8 annotations saved in the output folder.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Define the classes (you can modify this according to your XML)\n",
        "# classes = {'D20': 0, 'D40': 1, 'D10': 2, 'D00': 3, 'D50' : 4,'D44' : 5,'D43' : 6}\n",
        "\n",
        "# Function to convert XML annotations to YOLO v8 format\n",
        "\n",
        "\n",
        "# Input and output folder paths\n",
        "input_folder = 'annotations_xml'\n",
        "output_folder = 'labels'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through each XML file in the input folder\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith('.xml'):\n",
        "        xml_file_path = os.path.join(input_folder, file_name)\n",
        "        xml_to_yolo(xml_file_path, output_folder)\n",
        "\n",
        "print(\"Conversion successful. YOLO v8 annotations saved in the output folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2iZB2_nPw4B",
        "outputId": "a438526c-6d9b-4739-96f4-238145d4eb9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 'images' to 'data/images'\n",
            "Copied 'labels' to 'data/labels'\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "def copy_folders(source_folders, destination_folder):\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Iterate through each source folder\n",
        "    for source_folder in source_folders:\n",
        "        # Get the name of the source folder\n",
        "        folder_name = os.path.basename(source_folder)\n",
        "        # Construct the destination folder path\n",
        "        destination_folder_path = os.path.join(destination_folder, folder_name)\n",
        "\n",
        "        # Copy the entire folder and its contents to the destination folder\n",
        "        shutil.copytree(source_folder, destination_folder_path)\n",
        "        print(f\"Copied '{source_folder}' to '{destination_folder_path}'\")\n",
        "\n",
        "# Example usage:\n",
        "source_folders = ['images', 'labels']  # Replace with the paths to your source folders\n",
        "destination_folder = 'data'  # Replace with the path to the destination folder\n",
        "copy_folders(source_folders, destination_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VppyMM7GHKqE",
        "outputId": "a0d5c916-9940-400c-ec97-71da322af899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.24-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m719.5/719.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.24\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x-ooknzOl5Z",
        "outputId": "94bbf661-56a7-4d7b-cc70-5336622b7365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=config.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 36.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels... 21041 images, 6472 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21041/21041 [00:11<00:00, 1810.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/data/images/Japan_006916.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels.cache... 21041 images, 6472 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21041/21041 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/data/images/Japan_006916.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      2.47G      3.384      4.846      3.461          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1316/1316 [10:20<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 658/658 [05:23<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21041      34701      0.232     0.0306     0.0158    0.00405\n",
            "\n",
            "1 epochs completed in 0.266 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 658/658 [05:07<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21041      34701      0.231     0.0307     0.0158    0.00406\n",
            "                   D40      21041       3580      0.183    0.00924     0.0125    0.00348\n",
            "                   D20      21041       8381     0.0956      0.119     0.0347     0.0102\n",
            "                   D10      21041       6592          1          0    0.00382   0.000898\n",
            "                   D00      21041       5057      0.156     0.0501     0.0366     0.0108\n",
            "                   D50      21041       4446      0.659   0.000225    0.00943    0.00265\n",
            "                   D44      21041       5627     0.0272     0.0121    0.00525    0.00153\n",
            "                   D43      21041        793      0.191      0.116     0.0562      0.011\n",
            "                   D01      21041        179          0          0          0          0\n",
            "                   D11      21041         45          0          0          0          0\n",
            "                  D0w0      21041          1          0          0          0          0\n",
            "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.yaml\")\n",
        "\n",
        "results = model.train(data = ('config.yaml'),epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opz3Etd4UNs2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}